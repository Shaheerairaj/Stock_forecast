{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1umcE4l8b9n1JOpvOJboUiSjUPmakunPL","timestamp":1721827235606},{"file_id":"16DueNVLqA-qv8n2RnW61xW0bdpfsU-rZ","timestamp":1721323875078}],"authorship_tag":"ABX9TyPmEpSvYFV5jh4PUGxS5o8z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Definition of YahooTicker object\n","OOP model for Application"],"metadata":{"id":"37gNKcfw8DdB"}},{"cell_type":"markdown","source":["# Install pckages"],"metadata":{"id":"OkfYzxNO55az"}},{"cell_type":"code","source":["!pip install yfinance\n","!pip install pandas\n","!pip install numpy"],"metadata":{"id":"sv3azCoGDpLx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721827975107,"user_tz":-120,"elapsed":35739,"user":{"displayName":"Oleg Kalenskyy","userId":"05045291457635877026"}},"outputId":"bb1e64ea-8fd6-4ee9-a5f5-fcb142c1340a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.40)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.0.3)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n","Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.7.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"]}]},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"J5Zy_SVnyPFD"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EOsO-Wlm7GiU"}},{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import MinMaxScaler\n"],"metadata":{"id":"_dNo806e6T1T","executionInfo":{"status":"ok","timestamp":1721827978889,"user_tz":-120,"elapsed":3784,"user":{"displayName":"Oleg Kalenskyy","userId":"05045291457635877026"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class YahooTicker():\n","    \"\"\"\n","    Class for fetching and processing historical stock data from Yahoo Finance API.\n","    \"\"\"\n","    def __init__(self, ticker, start_date, end_date):\n","        \"\"\"\n","        Initialise the YahooTicker class with minimum required parameters\n","        \"\"\"\n","        self.ticker:str = ticker\n","        self.start_date:str = start_date\n","        self.end_date:str = end_date\n","\n","        self._stock_data:pd.DataFrame = pd.DataFrame()\n","        self._dataset_columns:list = []\n","        self._dataset_size:int = 0\n","        self._training_data_percent:float = 0\n","        self._n_training_days:int = 0\n","        self._n_prediction_days:int = 0\n","        self._n_lags:int = 0\n","        self._target_column:str = None\n","        self._extra_features:list = []\n","\n","        self._scaler = {}\n","\n","        self._features_scaled = {}\n","\n","        self._columns_list:list = []\n","\n","        self._dataset_train:np.ndarray= np.empty(0)\n","        self._dataset_test:np.ndarray= np.empty(0)\n","\n","\n","        self._X_train:np.ndarray = np.empty(0)\n","        self._x_train:np.ndarray = np.empty(0)\n","\n","        self._X_test:np.ndarray = np.empty(0)\n","        self._x_test:np.ndarray = np.empty(0)\n","\n","        self._y_train:np.ndarray = np.empty(0)\n","\n","        self._real_stock_price:pd.DataFrame = pd.DataFrame()\n","\n","    #stock_data\n","    @property\n","    def stock_data(self):\n","        return self._stock_data\n","\n","    @stock_data.setter\n","    def stock_data(self, value):\n","        if not isinstance(value, pd.DataFrame):\n","            raise TypeError(\"stock_data must be a DataFrame\")\n","        self._stock_data = value\n","\n","    @stock_data.deleter\n","    def stock_data(self):\n","        raise AttributeError(\"Do not delete, stock_data can be set to None\")\n","\n","    #dataset_size\n","    @property\n","    def dataset_size(self):\n","        return self._dataset_size\n","\n","    @dataset_size.setter\n","    def dataset_size(self, value):\n","        if not isinstance(value, int):\n","            raise TypeError(\"dataset_size must be a int\")\n","        self._dataset_size = value\n","\n","    @dataset_size.deleter\n","    def dataset_size(self):\n","        raise AttributeError(\"Do not delete, dataset_size can be set to 0\")\n","\n","    #dataset_columns\n","    @property\n","    def dataset_columns(self):\n","        return self._dataset_columns\n","\n","    @dataset_columns.setter\n","    def dataset_columns(self, value):\n","        if not isinstance(value, list):\n","            raise TypeError(\"dataset_size must be a list\")\n","        self._dataset_columns = value\n","\n","    @dataset_columns.deleter\n","    def dataset_columns(self):\n","        raise AttributeError(\"Do not delete, dataset_columns can be set to []\")\n","\n","    #training_data_percent\n","    @property\n","    def training_data_percent(self):\n","        return self._training_data_percent\n","\n","    @training_data_percent.setter\n","    def training_data_percent(self, value):\n","        if not isinstance(value, float):\n","            raise TypeError(\"training_data_percent must be a float\")\n","        if value > 1 or value < 0:\n","            raise ValueError(\"training_data_percent must be between 0 and 1.\")\n","        self._training_data_percent = value\n","\n","    @training_data_percent.deleter\n","    def training_data_percent(self):\n","        raise AttributeError(\"Do not delete, training_data_percent can be set to 0\")\n","\n","    #n_training_days\n","    @property\n","    def n_training_days(self):\n","        return self._n_training_days\n","\n","    @n_training_days.setter\n","    def n_training_days(self, value):\n","        if not isinstance(value, int):\n","            raise TypeError(\"n_training_days must be a int\")\n","        self._n_training_days = value\n","    @n_training_days.deleter\n","    def n_training_days(self):\n","        raise AttributeError(\"Do not delete, n_training_days can be set to 0\")\n","\n","   #n_prediction_days\n","    @property\n","    def n_prediction_days(self):\n","        return self._n_prediction_days\n","\n","    @n_prediction_days.setter\n","    def n_prediction_days(self, value):\n","        if not isinstance(value, int):\n","            raise TypeError(\"n_prediction_days must be a int\")\n","        if value ==0:\n","          value = 1\n","        self._n_prediction_days = value\n","    @n_prediction_days.deleter\n","    def n_prediction_days(self):\n","        raise AttributeError(\"Do not delete, n_prediction_days can be set to 0\")\n","\n","    #n_lags\n","    @property\n","    def n_lags(self):\n","        return self._n_lags\n","\n","    @n_lags.setter\n","    def n_lags(self, value):\n","        if not isinstance(value, int):\n","            raise TypeError(\"n_lags must be a int\")\n","        if value < 1:\n","            raise ValueError(\"Number of lags must be at least 1.\")\n","        self._n_lags = value\n","    @n_lags.deleter\n","    def n_lags(self):\n","        raise AttributeError(\"Do not delete, n_lags can be set to 0\")\n","\n","    #target_column\n","    @property\n","    def target_column(self):\n","        return self._target_column\n","\n","    @target_column.setter\n","    def target_column(self, value):\n","        if not isinstance(value, str):\n","            raise TypeError(\"target_column must be a str\")\n","        self._target_column = value\n","    @target_column.deleter\n","    def target_column(self):\n","        raise AttributeError(\"Do not delete, target_column can be set to None\")\n","\n","    #extra_features\n","    @property\n","    def extra_features(self):\n","        return self._extra_features\n","\n","    @extra_features.setter\n","    def extra_features(self, value):\n","        if not isinstance(value, list):\n","            raise TypeError(\"extra_features must be a list\")\n","        self._extra_features = value\n","    @extra_features.deleter\n","    def extra_features(self):\n","        raise AttributeError(\"Do not delete, extra_features can be set to None\")\n","\n","    #scaler\n","    @property\n","    def scaler(self):\n","        return self._scaler\n","\n","    @scaler.setter\n","    def scaler(self, value):\n","        if not isinstance(value, MinMaxScaler):\n","            raise TypeError(\"sc_extra must be MinMaxScaler\")\n","        self._scaler = value\n","\n","    @scaler.deleter\n","    def scaler(self):\n","        raise AttributeError(\"Do not delete, scaler can be set to {}\")\n","\n","    #features_scaled\n","    @property\n","    def features_scaled(self):\n","        return self._features_scaled\n","\n","    @features_scaled.setter\n","    def features_scaled(self, value):\n","         if not isinstance(value, pd.DataFrame):\n","             raise TypeError(\"features_scaled must be pd.DataFrame\")\n","         self._features_scaled = value\n","\n","    @features_scaled.deleter\n","    def features_scaled(self):\n","        raise AttributeError(\"Do not delete, features_scaled can be set to {}\")\n","\n","    #columns_list\n","    @property\n","    def columns_list(self):\n","        return self._columns_list\n","\n","    @columns_list.setter\n","    def columns_list(self, value):\n","        if not isinstance(value, list ):\n","            raise TypeError(\"columns_list must be list\")\n","        self._columns_list = value\n","\n","    @columns_list.deleter\n","    def columns_list(self):\n","        raise AttributeError(\"Do not delete, columns_list can be set to []\")\n","\n","    #dataset_train\n","    @property\n","    def dataset_train(self):\n","        return self._dataset_train\n","\n","    @dataset_train.setter\n","    def dataset_train(self, value):\n","         self._dataset_train = value\n","\n","    @dataset_train.deleter\n","    def dataset_train(self):\n","        raise AttributeError(\"Do not delete, dataset_train can be set to empty\")\n","\n","    #dataset_test\n","    @property\n","    def dataset_test(self):\n","        return self._dataset_test\n","\n","    @dataset_test.setter\n","    def dataset_test(self, value):\n","        self._dataset_test = value\n","\n","    @dataset_test.deleter\n","    def dataset_test(self):\n","        raise AttributeError(\"Do not delete, dataset_test can be set to empty\")\n","\n","    #X_train\n","    @property\n","    def X_train(self):\n","        return self._X_train\n","\n","    @X_train.setter\n","    def X_train(self, value):\n","        self._X_train = value\n","\n","    @X_train.deleter\n","    def X_train(self):\n","        raise AttributeError(\"Do not delete, X_train can be set to []\")\n","\n","    #x_train\n","    @property\n","    def x_train(self):\n","        return self._x_train\n","\n","    @x_train.setter\n","    def x_train(self, value):\n","        self._x_train = value\n","\n","    @x_train.deleter\n","    def x_train(self):\n","        raise AttributeError(\"Do not delete, x_train can be set to []\")\n","\n","    #x_test\n","    @property\n","    def x_test(self):\n","        return self._x_test\n","\n","    @x_test.setter\n","    def x_test(self, value):\n","        if not isinstance(value, np.ndarray):\n","             raise TypeError(\"x_test must be array\")\n","        self._x_test = value\n","\n","    @x_test.deleter\n","    def x_test(self):\n","        raise AttributeError(\"Do not delete, x_test can be set to []\")\n","\n","    #X_test\n","    @property\n","    def X_test(self):\n","        return self._X_test\n","\n","    @X_test.setter\n","    def X_test(self, value):\n","        if not isinstance(value, np.ndarray):\n","            raise TypeError(\"X_test must be array\")\n","        self._X_test = value\n","\n","    @X_test.deleter\n","    def X_test(self):\n","        raise AttributeError(\"Do not delete, X_test can be set to []\")\n","\n","    #y_train\n","    @property\n","    def y_train(self):\n","        return self._y_train\n","\n","    @y_train.setter\n","    def y_train(self, value):\n","        if not isinstance(value, np.ndarray):\n","            raise TypeError(\"y_train must be darray\")\n","        self._y_train = value\n","\n","    @y_train.deleter\n","    def y_train(self):\n","        raise AttributeError(\"Do not delete, y_train can be set to []\")\n","\n","    #real_stock_price\n","    @property\n","    def real_stock_price(self):\n","        return self._real_stock_price\n","\n","    @real_stock_price.setter\n","    def real_stock_price(self, value):\n","        if not isinstance(value, pd.DataFrame):\n","            raise TypeError(\"real_stock_price must be DataFrame\")\n","        self._real_stock_price = value\n","\n","    @real_stock_price.deleter\n","    def real_stock_price(self):\n","        raise AttributeError(\"Do not delete, real_stock_price can be set to []\")\n","\n","# +------------------------------------------------------------------------+\n","# |        Methods                                                         |\n","# +------------------------------------------------------------------------+\n","\n","\n","    def _split_dataset(self)->None:\n","        \"\"\"\n","        Split the dataset into training and testing sets.\n","        Protected method\n","        \"\"\"\n","        self.n_training_days = int(self.dataset_size * self.training_data_percent)\n","        self.dataset_train, self.dataset_test = self.stock_data.iloc[:self.n_training_days], self.stock_data.iloc[self.n_training_days:]\n","\n","    def _scale_features(self)->None:\n","        \"\"\"\n","        Scale the features using MinMaxScaler.\n","        Protected method\n","        \"\"\"\n","        for f in self.columns_list:\n","            self.scaler[f] = MinMaxScaler(feature_range=(0, 1))\n","            self.features_scaled[f] = self.scaler[f].fit_transform(self.dataset_train[[f]].values)\n","\n","    def _create_data_structure(self)->None:\n","        \"\"\"\n","        Create a data structure with n_lags timesteps and step output.\n","        Protected method\n","        \"\"\"\n","        X_train = []\n","        y_train = []\n","        for i in range(self.n_lags, len(self.features_scaled[self.target_column])-self.n_prediction_days):\n","            x_train=self.features_scaled[self.target_column][i-self.n_lags:i].squeeze()\n","\n","            for f in self.extra_features:\n","                x_train = np.hstack((x_train, self.features_scaled[f][i-self.n_lags:i].squeeze()))\n","\n","            X_train.append(x_train)\n","            y_train.append(self.features_scaled[self.target_column][i + self.n_prediction_days])\n","            # y_train.append(self.dataset_train[self.target_column][i + self.n_prediction_days])\n","\n","        self.X_train, self.y_train = np.array(X_train), np.array(y_train)\n","\n","    def _prepare_test_set(self)->None:\n","        \"\"\"\n","        Prepare the test set for evaluation.\n","        Protected method\n","        \"\"\"\n","\n","        self.real_stock_price = self.dataset_test[self.columns_list]\n","        dataset_total = pd.concat((self.dataset_train[self.columns_list], self.dataset_test[self.columns_list]), axis=0)\n","        dataset_total = dataset_total[len(dataset_total)-len(self.dataset_test)-self.n_lags:]\n","\n","        for f in self.columns_list:\n","            dataset_total[f] = self.scaler[f].transform(dataset_total[[f]])\n","\n","        X_test = []\n","        x_test = []\n","\n","        for i in range(self.n_lags, len(dataset_total)-self.n_prediction_days):\n","          x_test = dataset_total[self.target_column][i-self.n_lags:i].values\n","          for f in self.extra_features:\n","              x_test = np.hstack((x_test, dataset_total[f][i - self.n_lags:i].values))\n","          X_test.append(x_test)\n","        X_test = np.array(X_test)\n","\n","        self.X_test = X_test\n","\n","\n","    def _reshape_for_lstm(self)->None:\n","        \"\"\"\n","        Reshape the data for LSTM.\n","        Protected method\n","        \"\"\"\n","        self.X_train = np.reshape(self.X_train, (self.X_train.shape[0], self.n_lags, len(self.columns_list)))\n","        self.X_test = np.reshape(self.X_test, (self.X_test.shape[0], self.n_lags, len(self.columns_list)))\n","\n","\n","\n","    def fetch_data(self):\n","        \"\"\"\n","        Fetch historical data from Yahoo Finance API.\n","        \"\"\"\n","        self.stock_data:pd.DataFrame = pd.DataFrame(yf.download(self.ticker, start=self.start_date, end=self.end_date))\n","        self.dataset_size = len(self.stock_data)\n","        self.dataset_columns = self.stock_data.columns.tolist()\n","\n","    def prepare_data_feat_step(self, training_data_percent:float = 0.2, n_lags:int=60, predict_days:int=0, target_column:str=None, extra_features=[], reshape_for_lstm:bool=False)->tuple:\n","        \"\"\"\n","        Prepare the data for training and testing.\n","\n","        Prepares data for LSTM model considering a window of n_lags past observations to create X_train and X_test.\n","        y_train is prepared for long-term forecasting with a specified forecast horizon.\n","        IMPUT Arg:\n","            training_data_percent (float)  - define the %% of data to be used for training. The value is strictly between 0 and 1, default 0.2\n","            n_lags (int) - Number of past observations to use as features. Default value = 60\n","            predict_days (int) - Required number of days to be forecasted. Default value = 0 - the forecast for the next day\n","            target_columnn (str) - The name of the target column in the dataset. This argument is mandatory.\n","            extra_features (array) - List of extra features to be included in the dataset. Default value = []\n","        OUTPUT:\n","            tuple\n","                X_train (pd.DataFrame) Training features\n","                y_train (pd.DataFrame) Training targets\n","                X_test (pd.DataFrame)  Testing features\n","                real_stock_price (pd.DataFrame) Real stock prices for comparison\n","                sc_target (MinMaxScaler) Object used for scaling the target column\n","        \"\"\"\n","\n","        self.training_data_percent = training_data_percent\n","        self.n_lags = n_lags\n","        self.n_prediction_days = predict_days\n","        self.target_column = target_column\n","        self.extra_features = extra_features\n","        self.columns_list = [self.target_column] + self.extra_features\n","\n","        self._split_dataset()\n","        self._scale_features()\n","        self._create_data_structure()\n","        self._prepare_test_set()\n","\n","        if reshape_for_lstm:\n","            self._reshape_for_lstm()\n","\n","        return(self.X_train, self.y_train, self.X_test, self.real_stock_price, self.scaler[self.target_column])\n"],"metadata":{"id":"J8sdHSxYvYUA","executionInfo":{"status":"ok","timestamp":1721828161868,"user_tz":-120,"elapsed":3,"user":{"displayName":"Oleg Kalenskyy","userId":"05045291457635877026"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"r2WjBUR96m9F"}},{"cell_type":"code","source":["# Test box\n","\n","# Create an instance of the class\n","AaplTicker = YahooTicker(\"AAPL\", '2021-01-01', '2024-07-01')\n","# Call the fetch_data() method\n","AaplTicker.fetch_data()\n","\n","X_train, y_train, X_test, y_test, scaler = AaplTicker.prepare_data_feat_step(n_lags = 60, target_column='Open',extra_features=['Close'])\n","\n","\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)\n","print(scaler)\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvC0oV_eyhd3","executionInfo":{"status":"ok","timestamp":1721828220616,"user_tz":-120,"elapsed":272,"user":{"displayName":"Oleg Kalenskyy","userId":"05045291457635877026"}},"outputId":"3764958a-83a6-4a99-d65b-82bc346d6a65"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["\r[*********************100%%**********************]  1 of 1 completed"]},{"output_type":"stream","name":"stdout","text":["(114, 120)\n","(114, 1)\n","(701, 120)\n","(702, 2)\n","MinMaxScaler()\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n","  warnings.warn(\n"]}]}]}